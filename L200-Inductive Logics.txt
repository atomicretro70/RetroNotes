##############################################################################
##############################################################################
##############################################################################
##############################################################################
######                                                                  ######
######                                                                  ######
######                                                                  ######
######                                                                  ######
######          ##############################################          ######
######          ##############################################          ######
######          ###                                        ###          ######
######          ###              Retro Notes               ###          ######
######          ###                                        ###          ######
######          ###          Methods of Induction          ###          ######
######          ###                                        ###          ######
######          ##############################################          ######
######          ##############################################          ######
######                                                                  ######
######                                                                  ######
######                                                                  ######
######                                                                  ######
######                                                                  ######
######                                                                  ######
######                                                                  ######
######                     AtomicRetro@outlook.com                      ######
######                                                                  ######
######                     Revision:  20.10.05                          ######
######                                                                  ######
######                                                                  ######
######                                                                  ######
##############################################################################
##############################################################################
##############################################################################
##############################################################################

....|....1....|....2....|....3....|....4....|....5....|....6....|....7....|...


==============================
To View This Document Properly
==============================
* Best if viewed in VIM using with settings
     :set columns=80
     :set encoding=utf-8

* This document must be viewed with a mono-spaced font to enjoy the layout,
  tables and diagrams.

* This document must be viewed in an editor that can display unicode utf-8.


=========
Induction
=========

An INDUCTIVE ARGUMENT is an argument where the conclusion is only probable
given the premises.

The INDUCTIVE PROBABILITY is the probability of the conclusion.  The
inductive probability depends upon the relative strengths of the premises and
conclusion.


------------------
Statement Strength
------------------

   A STATEMENT'S STRENGTH is approximately inversely related to it's a priori
   probability (probability prior to or in absence of evidence).

   A STRONG STATEMENT is a statement that says more.  It's strong
   regardless of truth.  These statements are true only under specific
   circumstances.  So they are less likely to be true.

   The STRONGEST statements say so much that they can't be true.  They are
   the contradictions and have a probability of 0.  They're so strong they
   entail all other statements.

   A WEAK STATEMENT says less.  These statements are true under a
   wider variety of circumstances.  The weaker it is the more probable
   it is.

   The WEAKEST statements are those which are logically necessary.  They're
   true in all possible circumstances, in a sense they say nothing at all.
   These statements have a probability of 1.

   Negating strong and weak
   The negation of a weak statement is strong and the negation of a strong
   statement is weak.

   It's generally impossible to assign an exact strength to statements but
   the following rules might be helpful for some sets of statements.

      1.  If statement A deductively implies statement B, but B does not
          deductively imply A, then A is stronger than B. (The circumstances
          in which A are true is a subset of those in which B is true).

      2.  If statement A is logically equivalent to statement B (each
          deductively implies the other), then A and B are equally strong.

   INDUCTIVE PROBABILITY the the probability of the conclusion of an
   inductive argument.  In general inductive probability tends to vary with
   the strength of the premises and inversely with the strength of the
   conclusion.  Strengthening the premises or weakening the conclusion may
   not necessarily increase the argument's inductive probability, but such
   cases are rare.


-------------------------
Inductive Arguments Types
-------------------------

   Uniformity Suppositon

   Inductive arguments are divisible into two types according to whether
   they presuppose that the uniserse or some aspect of it is or is likely
   to be uniform or lawlike.

   STATISTICAL ARGUMENTS are those that do not require this presupposition.
   The premises of such an argument support the conclusion for purely
   statistical or mathematical reasons.

      98% of college freshmen can read beyond the sixth grade level.
      Dave is a college freshman.
      ∴ Dave can read beyond the sixth grade level.

      Which has an inductive probability of 0.98 under the logical
      interpretation.

   HUMEAN ARGUMENTS require the uniformity supposition.

      Each of the 100 freshment surveyed knew how to spell 'logic'.
      ∴ If we ask another freshman, they will know how to spell 'logic'.


=====================
Statistical Arguments
=====================


----------------------
Statistical Syllogisms
----------------------

   These arguments are strongest when n=1, weakest when n=0. They're also
   Deductive if n=1.

   0 <= n <= 100

      n% of F are G.
      x is F.
      [That's all we know about the matter.]
      ∴ It's n% probable that, x is G.

   n >= 50

      n% of F are G.
      x is F.
      [That's all we know about the matter.]
      ∴ probably x is G.  or,
      ∴ x is G.

      The inductive probability of this Syllogism is n/100 under the
      logical interpretation.

   n < 50

      n% of F are G.
      x is F.
      [That's all we know about the matter.]
      ∴ probably x is not G.  or,
      ∴ x is not G.

      The inductive probability of this Syllogism is 1 - n/100 under the
      logical interpretation.


--------------------------
Statistical Generalization
--------------------------

      n% of s randomly selected F are G. (s = sample size)
      ∴ About n% of all F are G.

      n% of examined F are G.
      A large and varied group of F has been examined.
      ∴ Probably roughly n% of all F are G.

   The inductive probability of statistical generalizations is mainly a
   function of two quantities: the sample size s (stengthening the
   premise), and the strength of the conclusion (weakened by increasing
   the margin of error which is why the 'about' is in the conclusion.


================
Humean Arguments
================

Humean arguments require a presupposition that the universe or some aspect
of it is or is likely to be uniform or lawlike; such as that the future will
resemble the past.

Inductive Generalization (Weak conclusion)

      n% of s thus-far-observed F are G. (s = sample size)
      ∴ About n% of all F are G.

Scientific Induction (Weaker conclusion)

      All the s thus-far-observed F are G. (n=1.0, s = sample size)
      ∴ All F are G.

Simple Induction (Weakest conclusion)

   (Induction by Enumeration, Simple Predictive Inference)
   Here the population mentioned is reduced to one individual.
   The inductive probability is strongest when n=1.0, and weakest when n=0.

      n% of s thus-far-observed F are G.
      ∴ If one more F is observed, it will be G.

   Simple inductions have much stronger inductive probabilities than
   inductive generalizations.

Argument from Authority

   An expert in a field can consist of a persor or persons, or something
   like a book.

      Such-and-such expert in the field asserts/advises/warns P.
      ∴ P.

Argument from a Sign

      That posted sign claims P.
      ∴ P.


--------------------
Analogical Reasoning
--------------------

Analogies are another kind of humean arguments.  An ANALOGY is simply
a structured argument which identifies similar properties among two objects,
and then asserts that one further property must also be shared among them.
It then proceeds to reason that because one of the objects possess another
property G, that the second must also possess the property G.

   Both x and y have property P1.
   Both x and y have property P2.
   Both x and y have property P3.
   ...
   x has property Q.
   ∴ y also has property Q.

We can strengthen the analogical argument (strengthen its inductive
probability) by strengthening the premises, or by weakening the conclusion.
Listing more shared properties strengthens the arguments.  Some properties
count more towards the strength than others where broad properties don't
add much strength while very specific properties do.  Also significant is
how relevant the shared properties are to the final property Q.

Conclusions of analogies have some of the weakest inductive probabilites for
any kind of inductive argument.


---------------------------------
Causal Reasoning (Mill's Methods)
---------------------------------

In causal reasoning, we start with an effect and reason backwards to a cause.

Method of Agreement (Necessary Condition)

   The method of agreement identifies a cause in the sense of a necessary
   condition.

   This method is used when all occurrences experience the effect.

   In this method we set up a table in which each occurrence of an effect
   is listed down the side, and possible necessary conditions (possible
   causes) are listed along the top.  A final column is added which lists
   the phenomenon experienced and in which occurrences the effect in
   question was experienced.

   Example
      If we imagine a scenario where a group of people become sick after
      eating at a reastauant.  The occurrences are the people who visited
      the restaurant.  The Phenomenon column indicates all those who because
      sick.  The remining columns list all of the possible things that could
      have caused the sickness.  The condition column which is completely
      selected is the necessary cause.

              |   Possible Necessary Conditions                  | phenom
   Occurrence | apple | beer | corn | dill | eggs | fish | grape | (sickness)
   -----------+-------+------+------+------+------+------+-------+--------
   alice      |   *             *      *             *      *        *
   bob        |   *      *      *             *      *      *        *
   charlie    |          *             *             *               *
   david      |   *      *                    *      *      *        *
   ellen      |   *             *             *      *      *        *

   Notice that everybody who got sick had the fish.  Therefore, the fish is
   the necessary condition.

Method of Difference (Sufficient Condition)

   This method limits itself to just two occurrences where both occurrences
   are otherwise very similar (like identical twins), but the effect only
   happens in one of the two occurrences.

              |   Possible Sufficient Conditions                 | phenom
   Occurrence | apple | beer | corn | dill | eggs | fish | grape | (sickness)
   -----------+-------+------+------+------+------+------+-------+--------
   alice      |   *      *      *      *      *      *      *        *
   betty      |   *      *      *      *      *      *

   From the table we see that having the grapes is a sufficient condition
   for the sickness to occur.

   Sometimes a possible sufficient condition is a lack or absense of
   something.

Joint Method of Agreement and Difference (Necessary or Sufficient Conditions)

   Use when some occurrences experienced the effect and some didn't.

              |   Possible Necessary Conditions                  | phenom
   Occurrence | apple | beer | corn | dill | eggs | fish | grape | (sickness)
   -----------+-------+------+------+------+------+------+-------+--------
   alice      |          *      *             *      *      *        *
   bob        |   *      *             *      *             *        *
   charlie    |   *             *             *      *               *
   david      |   *             *                    *                
   ellen      |                        *                    *         
   frida      |          *      *                    *

   So here the eggs were both a necessary and sufficient condition of
   the sickness.

Method of Residues

   This is a logical reasoning method rather than a table method.  It's
   useful in a situation where several possible causes are creating some
   effects.  One proceeds by eliminatig cause/effect pairs until one cause
   remains for a linger effect.

      A, B, ..., C  is the combination of possible conditions causing
                    effects a,b,...,c
      A has been found to cause effect a.
      B has been found to cause effect b.
      ∴ C must be the cause of the remaining effect c.

   The conclusion follows probably because it's quite possible other
   possible conditions haven't been identified.

Method of Concomitant Variation

      A,B,...,C possible causes coincide with effects X,Y,...,Z
      B varies upwards when Y varies upwards
      B varies downwards when Y varies downwards
      ∴ B is causally connected to Y.


==================
Probability Theory
==================

In addition to the Statistical Arguments presented above.  There is also
a theory that can help us compute probabilites for related events.  This
Theory is in widespread used.  The theorems we derive will be the basis
for the computations.

The probability function

   The probability function P assigns probabilites in different ways
   depending upon the interpretation.

   subjective interpretation
      P(A) stands for the degree of belief a particular rational person
      has in proposition A at a given time.  Degree of belief is gauged
      behaviorally by the person's willingness to accept certain bets on
      the truth of A.

   logical interpretation
      P(A) designates the logical or a priori (guess in the absense of
      evidence) probability of A.  P(A) varies inversely with the
      information content of A.  So if A is a weak proposition whose
      information content is small, P(A) tends to be high, and if A
      is strong with great information content then P(A) tends low.

   frequency interpretation
      A is usually taken to be an event and  P(A) is the frequency of
      occurrence of E relative to some specified reference class of
      events.  It's the most often used interepretation in math and stats.

   classical interpretation
      A is usually taken to be an event.  Probabilities can only be
      defined when a situation has a finite nonzero number of equally
      likely possible outcomes such as a fair die.  P(A) then is
      defined as the raio of the number of possible outcomes in which E
      occurs to the total number of possible outcomes.

                Num possible outcomes in which A occurs
         P(A) = ---------------------------------------
                      Total num possible outcomes

The Probability Axioms

   Ax1.   P(A) >= 0
   Ax2.   If A is tautologous, P(A) = 1
   Ax3.   If A,B are mutually exclusive, P(A ∨ B) = P(A) + P(B)

   Mutual Exclusivity
      Mutually exclusive means that under no conditions can both
      A and B occur.

Important Theorems

   PTH03.   P(-A) = 1 - P(A)

      Proof: Since A ∨ -A is tautologous, by Ax2 P(A ∨ -A) = 1, and since A
      and -A are mutually exclusive then by Ax3 P(A ∨ -A) = P(A) + P(-A) = 1.
      Subtracting P(A) from both sides P(-A) = 1 - P(A). QED

   PTH04.   If A is contradictory, P(A) = 0

      Proof: Suppose A is contradictory, then -A is tautologous.  So, by Ax2
      P(-A) = 1.  By theorem PTH03 we know that P(-A) = 1 - P(A).
      So, 1 - P(A) = 1.  Adding P(A) to both sides we get 1 = 1 + P(A),
      and subtracting 1 from both sides we get. 0 = P(A) or P(A) = 0.
      Therefore, by conditional proof, if A is contradictory then P(A) = 0.
      QED

   PTH05.   0 <= P(A) <= 1

      Proof: By Ax1 we know that 0 <= P(A) so that settles the lower bound.
      We also know that 0 <= P(-A) and from PTH01 P(-A) = 1 - P(A).  So,
      0 <= 1 - P(A).  Adding P(A) to both sides P(A) <= 1.  So,
      p <= P(A) <= 1. QED

   PTH06.   If A,B are truth-functionally equivalent, then P(A) = P(B).

      Proof: Suppose that A,B are truth-functionally equivalent, then A,B
      have the same truth conditions.  Hence, A,-B must always have opposite
      truth values.  So A,-B are mutually exclusive, and A ∨ -B is a
      tautology.  P(A ∨ -B) = 1 = P(A) + P(-B).  From PTH1 
      1 = P(A) + 1 - P(B).  Add P(B) to both sides, 1 + P(B) = P(A) + 1.
      Finally, subtracting 1 from both sides, P(B) = P(A).  Therefore,
      by conditional proof, if A,B are truth-functionally equivalent,
      then P(A) = P(B). QED

   PTH07.   P(A ∨ B) = P(A) + P(B) - P(A ∧ B)

      Proof:
      (a)  A is truth-functionally equivalent to (A ∧ B) ∨ (A ∧ -B).
      (b)  B is truth-functionally equivalent to (A ∧ B) ∨ (-A ∧ B).
      (c)  A ∨ B is truth-functionally equivalent to
           ((A ∧ -B) ∨ (-A ∧ B)) ∨ (A ∧ B).
      (d)  A ∧ B and ∧ -B are mutually exclusive
      (e)  A ∧ B and -A ∧ B are mutually exclusive.
      (f)  (A ∧ -B) ∨ (-A ∧ B) and A ∧ B are mutually exclusive.
      (g)  A ∧ -B and -A ∧ B are mutually exclusive.

      By item (a) and PTH06, P(A) = P((A ∧ B) ∨ (A ∧ -B)), whence by item (d)
      and Ax3 it follows that:

      (h)  P(A) = P(A ∧ B) + P(A ∧ -B).

      Similarly, by item (b) and problem PTH06, P(B) = P((A ∧ B) ∨ (-A ∧ B)),
      whence by item (e) and Ax3 we get:

      (i)  P(B) = P(A ∧ B) + P(-A ∧ B).

      Moreover, from item (c) and PTH06 it follows that
      P(A ∨ B) = P(((A ∧ -B) ∨ (-A ∧ B)) ∨ (A ∧ B)), whence by item (f) and
      Ax3 we obtain P(A ∨ B) = P((A ∧ -B) ∨ (-A ∧ B)) + P(A ∧ B).  But then
      by (g) and Ax3 we see that:

      (j)  P(A ∨ B) = P(A ∧ -B) + P(-A ∧ B) + P(A ∧ B).

      Now by adding the equations in (h) and (i), we note that:

      (k)  P(A) + P(B) = P(A ∧ -B) + P(-A ∧ B) + 2P(A ∧ B).

      That is, if we simply add P(A) and P(B), where A and B are not
      mutually exclusive (i.e. P(A ∧ B) > 0), P(A ∧ B) will be counted twice.
      But as (j) tells us, the correct value for P(A ∨ B) is obtained by
      counting P(A ∧ B) only once.  Now, subtracting the equation in (k) from
      that in (j), we obtain:

      (l) P(A ∨ B) = (P(A) + P(B)) = -P(A ∧ B).

      Adding P(A) + P(B) to both sides of this equation yields
      P(A ∨ B) = P(A) + P(B) - P(A ∧ B)
      QED

   PTH08.   P(A ∧ B) <= P(A) and P(A ∧ B) <= P(B)

      Proof: By (h) in the proof of PTH07, P(A) = P(A ∧ B) + P(A ∧ -B).
      But by Ax1, P(A ∧ -B) >= 0.  Since adding a nonnegative quantity
      to P(A ∧ B) gives P(A), it must be that P(A ∧ B) <= P(A).  Proof
      of the second conjunct is simiarl except that (j) from the proof
      of PTH07 is used. QED

   PTH09.   P(A ∨ B) >= P(A) and P(A ∨ B) >= P(B)

      Proof: By PTH07, P(A ∨ B) = P(A) + P(B) - P(A ∧ B). and by PTH08,
      P(B) - P(A ∧ B) >= 0.  Hence, P(A ∨ B) >= P(A). QED

   PTH10.   If P(A) = P(B) = 0, then P(A ∨ B) = 0

      Proof:  Suppose P(A) = P(B) = 0.  Then by problem PTH08 and Ax1,
      P(A ∧ B) = 0.  Hence, by PTH07 P(A ∨ B) = 0. QED

   PTH11.   If P(A)=1, then P(A ∧ B) = P(B)

      Proof:  Suppose P(A)=1, not by PTH09, P(A ∨ B) >= P(A), and by
      PTH05, P(A ∨ B) <= 1.  Hence P(A ∨ B) = 1.  By PTH07,
      P(A ∨ B) = P(A) + P(B) - P(A ∧ B), so that 1 = 1 + P(B) - P(A ∧ B);
      that is P(A ∧ B) = P(B). QED

   PTH12.   If A is a truth-functional consequence of B,
            then P(A ∧ B) = P(B).

      Proof:  Suppose A is a truth-functional consequence of B.  Then A ∧ B
      is truth-functionally equivalent to B, since A ∧ B is true on any line
      of a semantic table in which B is true and false on any line of a
      semantic table on which B is false.  So by PTH06, P(A ∧ B) = P(B).
      QED

   PDef01.  Conditional Probability

      Let A|B mean the probability of A given that B.  It's something *like*,
      but not the same as B -> A. QED

                   P(A ∧ B)
      P(A|B)  =df  --------
                     P(B)

      By the classical interpretation, P(A|B) is the proporition of possible
      outcomes in which A occurs among the possible outcomes in which B
      occurs.

      Example
         A die is tossed once.  Let E be 'the result of a toss is even',
         L be 'the result of the toss is less than 5'.  P(E|L) = ?.

                  P(E ∧ L)   2/6   2   6   12   1
         P(E|L) = -------- = --- = - * - = -- = -
                    P(L)     4/6   6   4   24   2
   
   PTH14.   P(A|A) = 1

      Proof: A ∧ A is TF equiv to A.  By PTH06,

               P(A ∧ A)   P(A)
      P(A|A) = -------- = ---- = 1
                 P(A)     P(A)

      QED

   PTH15.   P(-A|A) = 0

      Proof:  -A ∧ A is contradictory, and by PTH04 P(-A ∧ A) = 0. So,
      by PDef01,
                P(-A ∧ A)    0
      P(-A|A) = --------- = ---- = 0
                  P(A)      P(A)

      QED

   PTH16.   If B is tautologous, P(A|B) = P(A)

      Proof:  Suppose B is tautologous.  Then by Ax2, P(B) = 1.  Also, A ∧ B
      is TF equiv to A, so that by PTH06, P(A ∧ B) = P(A)

               P(A ∧ B)   P(A)
      P(A|B) = -------- = ---- = P(A)
                 P(B)      1

      QED

   PTH17.   If A,B are TF equiv, then P(A|C) = P(B|C).

      Proof:  Suppose A,B are TF equiv.  Then so are A ∧ C, and B ∧ C.
      So, by PTH06, P(A ∧ C) = P(B ∧ C).  Then by PDef01,

               P(A ∧ C)   P(B ∧ C)
      P(A|C) = -------- = -------- = P(B|C)
                 P(C)       P(C)

      QED

   PTH18.   If A,B are TF equiv, then P(C|A) = P(C|B).

      Proof:  Suppose A,B are TF equiv.  Then by PTH06, P(A) = P(B).
      By PTH17, P(C ∧ A) = P(C ∧ B).  Hence, by PDef01,

               P(C ∧ A)   P(C ∧ B)
      P(C|A) = -------- = -------- = P(C|B)
                 P(A)       P(B)

      QED

   PTH19.   P(A ∧ B) = P(A) * P(B|A)

      Proof:   PDef01 give P(B|A) = P(B ∧ A) / P(A).  Sicne B ∧ A is TF
      equiv to A ∧ B, by PTH06 we have P(B|A) = P(A ∧ B) / P(A).
      multiply both sides by P(A) yields the theorem. QED

   PTH20.   P(A)*P(B|A) = P(B)*P(A|B)

      Proof:  By PTH19, P(A ∧ B) = P(A) * P(B|A), and also'
      P(B ∧ A) = P(B) * P(A|B).  But A ∧ B is TF equiv to B ∧ A.  So by
      PTH06, P(A ∧ B) = P(B ∧ A).  This proves that the order of conjuncts
      is of no consequence. QED

   Independence

      It sometimes happens that P(A|B) = P(A), that is P(A) is unaffected
      by the occurrence of nonoccurrence of B.  In such cases we say that
      'A is independent of B'.

     Example: if A is the event of getting 1 on a first die toss, and B
     is getting a 1 on a second die toss, A is independent of B.

   PTH21.   P(A|B)=P(A) iff P(B|A)=P(B)
            ie. if A is indep of B, B is indep of A.

      Proof:  By PDef01, P(A|B)=P(A) iff P(A)=P(A ∧ B) / P(B).  Now multiply
      both sides by P(B)/P(A) gives P(B)=P(A ∧ B)/P(A), which (since A ∧ B
      is TF equiv to B ∧ A) is true iff P(B) = P(B ∧ A) / P(B); hence by
      PDef01, P(B) = P(B|A). QED

   Because of this symmetry, we can just say that 'A and B are independent'
   without regard to order.

   PTH22.   If A,B are indep, then P(A ∧ B) = P(A) ∧ P(B)

      Proof:  This follows immediately from PTH19 and the def of independence.
              QED

   PTH23.   Bayes' Theorem (Simple Version)

                     P(A) * P(B|A)
            P(A|B) = -------------
                        P(B)

      Proof:  This follows immediately from PTH20.  QED

      P(A) and P(B) are referred to as priors.

   Exhaustive Series

      A series of events A1,A2,...,An is exhaustive if
      P(A1 ∨ A2 ∨ ... ∨ An) = 1.

      Example, each of the outcomes of a die toss.

      Any series of the form, A ∧ B, A ∧ -B, -A ∧ B, -A ∧ -B is exhaustive.

   Pairwise Mutually Exclusive Series

      A series of propositions or events A1,A2,...,An is a pairwise
      mutually exclusive if for each pair Ai, Aj of its members
      P(Ai ∧ Aj) = 0.

      Example, each of the outcomes of a die toss.

   PTH24.   If A1,A2,...,An is a pariwise mutually exclusive and exhaustive
            series, then P(B) = P(A1 ∧ B) + P(A2 ∧ B) + ... + P(An ∧ B).

      Proof:  Too long.

   PTH25.   Bayes' Theorem (General Version)
            If A1,A2,...,An is a pairwise mutually exclusive and exhaustive
            series and Ai is some member of this series, then

                                    P(Ai)*P(B|Ai)
            P(Ai|B) = ---------------------------------------------------
                      P(A1)*P(B|A1) + P(A2)*P(B|A2) + ... + P(An)*P(B|An)

            Which cam be expressed more compactly as a summation

                          P(Ai)*P(B|Ai)
            P(Ai|B) = ---------------------
                        n
                       SIGMA P(Aj)*P(B|Aj)
                        j=1

   Hypothesis Testing

      Bayes' Theorem can be used to calculate the probability that a
      particular hypothesis accounts for a particular observation.  To do
      so we must formulate a series of hypotheses which is pariwise mutually
      exclusive and exhaustive - the series A1,A2,...,An mentioned in the
      theorem.  The observation is B.  To learn the probability that a
      particular member Ai of the series of hypotheses accounts for B -
      that is, P(Ai|B).

      To complete the calc, we need to know not only the probability of the
      observation B, given each of the hypotheses - that is, P(B|Aj) for
      each j such that 1 <= j <= n - but also the probability of each of
      the hypotheses, or P(Aj) for each such j.  The latter probabilities
      are called prior probabilities, or priors.  Theses can be difficult
      or impossible to determine.  It can be shown, however, that as
      observations accumulate, the priors have less and less influence on
      the computation result.  This phenomenon, known as "swamping the
      priors," permits useful application of Bayes' theorem even in cases
      in which the priors are only very roughly known.

   Example
      At a factory three machines produce girdles.  3/10 of girdles produced
      by machine1 are defective, as are 2/10 of those produced by machine2,
      and 1/10 of those of machine3.  Machine1 produces 4/10 of the factory
      output, machine2 produces 3/10, and machine3 produces 3/10.  Alma has
      received a defective girdle.  What's the Prob that it was produced by
      machine1, given that it's defective?

      Observation B is 'Alma's girdle is defective'.  Accounted for by 3
      pairwise mutually exclusive and exhaustive hypoth:

         A1 = Alma's girdle was produced on machine1.
         A2 = It was produced on machine2.
         A3 = It was produced on machine3.

      We may take the probability of B given each of these hypotheses as the
      respective proportion of defective girdles produced by each machine.

         P(B|A1) = 3/10
         P(B|A2) = 2/10
         P(B|A3) = 1/10

      Moreover, we have difinitive values for the priors in this case.  These
      are just the proportions of the total output of the factory produced
      by each machine:

         P(A1) = 4/10
         P(A2) = 3/10
         P(A3) = 3/10

                                      P(A1)*P(B|A1)
            P(A1|B) = ---------------------------------------------
                      P(A1)*P(B|A1) + P(A2)*P(B|A2) + P(A3)*P(B|A3)

                                  4/10*3/10  
            P(A1|B) = ---------------------------------
                      4/10*3/10 + 3/10*2/10 + 3/10*1/10   

                              12/100  
            P(A1|B) = ----------------------
                      12/100 + 6/100 + 3/100   

      
                      12/100  
            P(A1|B) = ------
                      21/100   

                       12   100   1200   12
            P(A1|B) = --- * --- = ---- = --
                      100    21   2100   21

   PTH27.   P(-A|B) = 1 - P(A|B)

   PTH28.   P(A ∨ B|C) = P(A|C) + P(B|C) - P(A ∧ B|C)

   PTH29.   P(A ∧ B|C) = P(A|C)*P(B|A ∧ C)

   PTH30.   P(A -> B) = P(-A) + P(A)*P(B|A)

